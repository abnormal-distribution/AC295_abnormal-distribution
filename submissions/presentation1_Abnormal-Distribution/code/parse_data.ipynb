{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.append('<num>')\n",
    "stopword_list = list(set(stopword_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopword list from NLTK\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.append('<num>')\n",
    "stopword_list = list(set(stopword_list))\n",
    "\n",
    "# Word counter for all words in dataset\n",
    "word_counter = Counter()\n",
    "\n",
    "categories = ['books', 'dvd', 'electronics', 'kitchen']\n",
    "classifications = ['positive.review', 'negative.review', 'unlabeled.review']\n",
    "\n",
    "for cat in categories:\n",
    "    for cl in classifications:\n",
    "        path = 'processed_acl/{}/{}'.format(cat, cl)\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        raw_split = [[rev.split(':') for rev in df.iloc[i].values[0].split()] \n",
    "                     for i in range(len(df))]\n",
    "        for review in raw_split:\n",
    "            for w_count in review:\n",
    "                # Ignore stopwords\n",
    "                if w_count[1].isdigit():# and w_count[0] not in stopword_list:\n",
    "                    word_counter[w_count[0]] += int(w_count[1])\n",
    "\n",
    "# 5000 most common words across all dataset\n",
    "common_words = [word[0] for word in word_counter.most_common(5000)]  \n",
    "# Dictionary mapping words to index in numpy array\n",
    "common_dict = {word:i for i, word in enumerate(common_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "0\n",
      "500\n",
      "0\n",
      "500\n",
      "0\n",
      "500\n",
      "0\n",
      "500\n",
      "0\n",
      "500\n",
      "0\n",
      "500\n",
      "0\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Make feature arrays for all labeled categories\n",
    "\n",
    "X_dict = {}\n",
    "\n",
    "for cat in categories:\n",
    "    X = np.zeros((2000,5000))\n",
    "    for cl_num, cl in enumerate(classifications[0:2]):\n",
    "        path = 'processed_acl/{}/{}'.format(cat, cl)\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        raw_split = [[rev.split(':') for rev in df.iloc[i].values[0].split()] \n",
    "                     for i in range(len(df))]\n",
    "        for r_num, review in enumerate(raw_split):\n",
    "            if r_num%500==0:\n",
    "                print(r_num)\n",
    "            for w_count in review:\n",
    "                if w_count[1].isdigit() and w_count[0] in common_words:\n",
    "                    X[cl_num*1000 + r_num, common_dict[w_count[0]]] = w_count[1]\n",
    "                    \n",
    "    X_dict[cat] = X.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Make feature arrays for all unlabeled categories\n",
    "\n",
    "X_unlabeled_dict = {}\n",
    "\n",
    "for cat in categories:\n",
    "    cl = classifications[2]\n",
    "\n",
    "    path = 'processed_acl/{}/{}'.format(cat, cl)\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    X = np.zeros((len(df),5000))\n",
    "    raw_split = [[rev.split(':') for rev in df.iloc[i].values[0].split()] \n",
    "                 for i in range(len(df))]\n",
    "    for r_num, review in enumerate(raw_split):\n",
    "        if r_num%1000==0:\n",
    "            print(r_num)\n",
    "        for w_count in review:\n",
    "            if w_count[1].isdigit() and w_count[0] in common_words:\n",
    "                X[r_num, common_dict[w_count[0]]] = w_count[1]\n",
    "                    \n",
    "    X_unlabeled_dict[cat] = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.ones(2000)\n",
    "Y[1000:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.ones(2000)\n",
    "Y[1000:] = 0\n",
    "categories = ['books', 'dvd', 'electronics', 'kitchen']\n",
    "cat_initial = ['B', 'D', 'E', 'K']\n",
    "\n",
    "for c1, i1 in zip(categories, cat_initial):\n",
    "    for c2, i2 in zip(categories, cat_initial):\n",
    "        \n",
    "        if c1!= c2:\n",
    "            d = [X_dict[c1], Y.copy(), X_dict[c2], Y.copy(), X_unlabeled_dict[c2]]\n",
    "            pickle.dump(d, open( \"{}-{}.pkl\".format(i1,i2), \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman_the:1 contains_the:1 fan_i:1 alex_ross(superman:1 justice:1 read:1 comics_fan:1 again:1 league_etc:1 fans:1 recieved:1 hanna-barbera!)_a:1 book_fans:1 wonder:1 gift:1 gorgeous_artwork:1 gift_and:1 contains:1 i_recieved:1 artwork:2 christmas:1 read_it:1 wonder_woman:1 justice_league:1 a_comics:1 again_and:1 even:1 i_read:1 the_most:2 gorgeous:1 of_alex:1 i:2 extraordinary:1 most_gorgeous:1 most:2 it_again:1 comic_books:1 and_i:1 ross(superman_batman:1 etc_even:1 etc:1 the_justice:1 fan:1 beautiful:1 again.a:1 even_hanna-barbera!):1 comics:1 batman_wonder:1 for_comic:1 in_comic:1 artwork_in:1 books_contains:1 woman:1 a_christmas:1 extraordinary_artwork:1 books:1 christmas_gift:1 ross(superman:1 league:1 artwork_of:1 most_extraordinary:1 comic_book:1 book:1 recieved_this:1 batman:1 must-have_for:1 hanna-barbera!):1 must-have:1 again.a_must-have:1 alex:1 and_again.a:1 comic:2 #label#:positive'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = 'books'\n",
    "cl = 'positive.review'\n",
    "\n",
    "path = 'processed_acl/{}/{}'.format(cat, cl)\n",
    "df = pd.read_csv(path, header=None)\n",
    "\n",
    "df[0][2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
