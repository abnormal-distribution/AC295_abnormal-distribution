{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.append('<num>')\n",
    "stopword_list = list(set(stopword_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopword list from NLTK\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.append('<num>')\n",
    "stopword_list = list(set(stopword_list))\n",
    "\n",
    "# Word counter for all words in dataset\n",
    "word_counter = Counter()\n",
    "\n",
    "categories = ['books', 'dvd', 'electronics', 'kitchen']\n",
    "classifications = ['positive.review', 'negative.review', 'unlabeled.review']\n",
    "\n",
    "for cat in categories:\n",
    "    for cl in classifications:\n",
    "        path = 'processed_acl/{}/{}'.format(cat, cl)\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        raw_split = [[rev.split(':') for rev in df.iloc[i].values[0].split()] \n",
    "                     for i in range(len(df))]\n",
    "        for review in raw_split:\n",
    "            for w_count in review:\n",
    "                # Ignore stopwords\n",
    "                if w_count[1].isdigit():# and w_count[0] not in stopword_list:\n",
    "                    word_counter[w_count[0]] += int(w_count[1])\n",
    "\n",
    "# 5000 most common words across all dataset\n",
    "common_words = [word[0] for word in word_counter.most_common(5000)]  \n",
    "# Dictionary mapping words to index in numpy array\n",
    "common_dict = {word:i for i, word in enumerate(common_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "0\n",
      "500\n",
      "0\n",
      "500\n",
      "0\n",
      "500\n",
      "0\n",
      "500\n",
      "0\n",
      "500\n",
      "0\n",
      "500\n",
      "0\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Make feature arrays for all labeled categories\n",
    "\n",
    "X_dict = {}\n",
    "\n",
    "for cat in categories:\n",
    "    X = np.zeros((2000,5000))\n",
    "    for cl_num, cl in enumerate(classifications[0:2]):\n",
    "        path = 'processed_acl/{}/{}'.format(cat, cl)\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        raw_split = [[rev.split(':') for rev in df.iloc[i].values[0].split()] \n",
    "                     for i in range(len(df))]\n",
    "        for r_num, review in enumerate(raw_split):\n",
    "            if r_num%500==0:\n",
    "                print(r_num)\n",
    "            for w_count in review:\n",
    "                if w_count[1].isdigit() and w_count[0] in common_words:\n",
    "                    X[cl_num*1000 + r_num, common_dict[w_count[0]]] = w_count[1]\n",
    "                    \n",
    "    X_dict[cat] = X.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Make feature arrays for all unlabeled categories\n",
    "\n",
    "X_unlabeled_dict = {}\n",
    "\n",
    "for cat in categories:\n",
    "    cl = classifications[2]\n",
    "\n",
    "    path = 'processed_acl/{}/{}'.format(cat, cl)\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    X = np.zeros((len(df),5000))\n",
    "    raw_split = [[rev.split(':') for rev in df.iloc[i].values[0].split()] \n",
    "                 for i in range(len(df))]\n",
    "    for r_num, review in enumerate(raw_split):\n",
    "        if r_num%1000==0:\n",
    "            print(r_num)\n",
    "        for w_count in review:\n",
    "            if w_count[1].isdigit() and w_count[0] in common_words:\n",
    "                X[r_num, common_dict[w_count[0]]] = w_count[1]\n",
    "                    \n",
    "    X_unlabeled_dict[cat] = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.ones(2000)\n",
    "Y[1000:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.ones(2000)\n",
    "Y[1000:] = 0\n",
    "categories = ['books', 'dvd', 'electronics', 'kitchen']\n",
    "cat_initial = ['B', 'D', 'E', 'K']\n",
    "\n",
    "for c1, i1 in zip(categories, cat_initial):\n",
    "    for c2, i2 in zip(categories, cat_initial):\n",
    "        \n",
    "        if c1!= c2:\n",
    "            d = [X_dict[c1], Y.copy(), X_dict[c2], Y.copy(), X_unlabeled_dict[c2]]\n",
    "            pickle.dump(d, open( \"{}-{}.pkl\".format(i1,i2), \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"avid:1 your:1 horrible_book:1 wasted:1 use_it:1 the_entire:1 money.i:1 i_lit:1 i_read:1 lit:1 i_would:1 relationship:1 read:1 a_<num>:1 reader_and:1 reader:1 suffering:1 fire_one:1 i_had:1 year_old:2 gotten:1 horrible:3 lit_this:1 world...don't:1 my:2 one_star:1 headache_the:1 this_book:5 mom:1 was_horrible:1 friend:1 book_horrible:1 star_i:1 back:1 avid_reader:1 than_one:1 life:1 copy:1 rate_it:1 rate:1 my_mom:1 man:1 book_was:1 half:1 on_fire:1 and_then:1 reading_this:1 so:1 lower:1 i_could:1 <num>_year:2 than:1 time:2 half_of:1 time_spent:1 then:1 book:6 and_picked:1 possible:1 spent:1 old_man:1 up_after:1 one:2 horrible_if:1 one_less:1 part:1 was:2 entire:1 less_copy:1 to_rate:1 my_life:1 about_the:1 your_money.i:1 an_avid:1 if:1 the_relationship:1 use:1 a_headache:1 fire:1 lower_than:1 reading:1 a_friend:1 picked:1 purposes:1 then_got:1 waste_your:1 after_my:1 friend_i:1 old:2 man_and:1 and_i:1 world...don't_waste:1 book_on:1 part_about:1 copy_in:1 book_back:1 book_wasted:1 have_i:1 time_and:1 the_world...don't:1 better:1 if_it:1 star:1 got:1 mom_had:1 read_half:1 waste:1 after:1 i:6 about:1 could_use:1 had_gotten:1 was_possible:1 year:2 it_lower:1 relationship_the:1 wasted_my:1 wish:1 wish_i:1 boy:1 purposes_this:1 got_to:1 the_time:1 it_was:1 back_so:1 suffering_from:1 spent_reading:1 book_up:1 less:1 better_purposes:1 headache:1 possible_to:1 money.i_wish:1 for_better:1 it_suffering:1 the_part:1 gotten_it:1 picked_this:1 entire_time:1 old_boy:1 i_am:1 the_<num>:1 boy_had:1 <num>:2 so_i:1 #label#:negative\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Xs, Ys, X_test, Y_test, Xt]=joblib.load(\"B-D.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
