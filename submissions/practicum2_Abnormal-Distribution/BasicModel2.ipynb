{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BasicModel2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "86C4-p4lR6jE",
        "tAIWevAc2XYI",
        "rOEndUuiaz7u",
        "fR7pciUW5__z",
        "SPWyyDZ90yFT",
        "i2QaSsOR6G6b"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "87f53882112140bdbe11bfe7ad42b0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_69c212ed44ca4c478563d25d61db064c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_642a2970deb84a8cbd084e854c809756",
              "IPY_MODEL_1f06fa3dc7fb4b7f88d14457c7a2759c"
            ]
          }
        },
        "69c212ed44ca4c478563d25d61db064c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "642a2970deb84a8cbd084e854c809756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f155ed3ac0f4558b8e567b2ffaec039",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29ff2e4a3565429e909f40a75b9c714a"
          }
        },
        "1f06fa3dc7fb4b7f88d14457c7a2759c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc264f53501a4d7a82777c61551b54d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:07&lt;00:00, 57.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2f91b44bb1744aea1e16db7dde48cd7"
          }
        },
        "1f155ed3ac0f4558b8e567b2ffaec039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29ff2e4a3565429e909f40a75b9c714a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc264f53501a4d7a82777c61551b54d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2f91b44bb1744aea1e16db7dde48cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "beabae3a77dd4a4883c2dc7a7a244f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_49578736331b4f038e79bfb037a7ccc7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cabfc24290ae49b694039dea2acd48a4",
              "IPY_MODEL_649e46e9b0724f47af98e27c0c527e12"
            ]
          }
        },
        "49578736331b4f038e79bfb037a7ccc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cabfc24290ae49b694039dea2acd48a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_530c7312a0804423be223997a53a933a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4db792a7f4c4ff69b48578f76da7db2"
          }
        },
        "649e46e9b0724f47af98e27c0c527e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41f672b0f28b432d9df5cb17dbc92d78",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 536M/536M [00:06&lt;00:00, 76.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6604b4a078d40a3b70dc0c4c838b311"
          }
        },
        "530c7312a0804423be223997a53a933a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4db792a7f4c4ff69b48578f76da7db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41f672b0f28b432d9df5cb17dbc92d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6604b4a078d40a3b70dc0c4c838b311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch6vpxrwQdcc"
      },
      "source": [
        "<h1 style=\"padding-top: 25px;padding-bottom: 25px;text-align: left; padding-left: 10px; background-color: #DDDDDD; \n",
        "    color: black;\"> <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> AC295: Advanced Practical Data Science </h1>\n",
        "\n",
        "## Practicum 2: Visual Question Answering\n",
        "\n",
        "**Harvard University, Fall 2020**  \n",
        "**Instructors**: Pavlos Protopapas  \n",
        "\n",
        "### **Team: $\\alpha\\beta normal$ $Distri\\beta ution$**\n",
        "#### **Roht Beri, Eduardo Peynetti, Jessica Wijaya, Stuart Neilson**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86zGynCVRsdD"
      },
      "source": [
        "## Basic Model for Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86C4-p4lR6jE"
      },
      "source": [
        "### Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyGrRhuBwNJb",
        "outputId": "ededca9d-3bd0-4ced-fe1c-adbbe9516eec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip3 install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 13.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 64.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 62.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=41175d635258fd5cbc6cefaf8dd051a2e6fee3eea94093199f87393f8069d5d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3idRbhCy12h9"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXHPXTLpQZ4V"
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import tempfile\n",
        "import zipfile\n",
        "import shutil\n",
        "import json\n",
        "import time\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import subprocess\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils.layer_utils import count_params\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "\n",
        "from transformers import BertTokenizer, TFBertModel"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAIWevAc2XYI"
      },
      "source": [
        "### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpYGZYyPucLA",
        "outputId": "9f1bc995-2487-4896-da33-954574b486aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if not os.path.exists('/content/data'):\n",
        "    os.mkdir('/content/data')\n",
        "\n",
        "!gsutil cp -r gs://practicum2-abnormal-distribution/big2 /content/data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://practicum2-abnormal-distribution/big2/answers.csv...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/train2014_tf/vaq_raw_train2014_00-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/train2014_tf/vaq_raw_train2014_01-of-10.records...\n",
            "| [3 files][  1.1 GiB/  1.1 GiB]  133.3 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://practicum2-abnormal-distribution/big2/train2014_tf/vaq_raw_train2014_02-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/train2014_tf/vaq_raw_train2014_03-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/train2014_tf/vaq_raw_train2014_04-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/train2014_tf/vaq_raw_train2014_05-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/train2014_tf/vaq_raw_train2014_06-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/train2014_tf/vaq_raw_train2014_07-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/train2014_tf/vaq_raw_train2014_08-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/train2014_tf/vaq_raw_train2014_09-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/train2014_tf/vaq_raw_train2014_10-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/val2014_tf/vaq_raw_val2014_00-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/val2014_tf/vaq_raw_val2014_01-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/val2014_tf/vaq_raw_val2014_02-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/val2014_tf/vaq_raw_val2014_03-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/val2014_tf/vaq_raw_val2014_04-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/val2014_tf/vaq_raw_val2014_05-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/val2014_tf/vaq_raw_val2014_06-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/val2014_tf/vaq_raw_val2014_07-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/val2014_tf/vaq_raw_val2014_08-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/val2014_tf/vaq_raw_val2014_09-of-10.records...\n",
            "Copying gs://practicum2-abnormal-distribution/big2/val2014_tf/vaq_raw_val2014_10-of-10.records...\n",
            "\\ [23 files][  8.5 GiB/  8.5 GiB]   57.9 MiB/s                                  \n",
            "Operation completed over 23 objects/8.5 GiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hN9E7Lw4czk",
        "outputId": "ba097172-43e5-4cab-f4a2-83b6ad2cd812",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#drive.mount('/content/drive', force_remount=False)\n",
        "if not os.path.exists('/content/data'):\n",
        "    os.mkdir('/content/data')\n",
        "\n",
        "#!cp -r '/content/drive/My Drive/Practicum2Data/big2' /content/data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDHE_Nd6SCy7"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJhxKghA_lci"
      },
      "source": [
        "# we use the following to save the models\n",
        "class JsonEncoder(json.JSONEncoder):\n",
        "  def default(self, obj):\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, decimal.Decimal):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    else:\n",
        "        return super(JsonEncoder, self).default(obj)\n",
        "\n",
        "# save_model saves everything. weights, statuses and results. \n",
        "def save_model(model,training_results,execution_time, learning_rate, epochs, optimizer, evaluation_results,\n",
        "               path=\"/content/drive/My Drive/Practicum2Data/models\"):\n",
        "  model_name = model.name\n",
        "  # Get the model train history\n",
        "  model_train_history = training_results.history\n",
        "\n",
        "  # Ensure path exists\n",
        "  if not os.path.exists(path):\n",
        "      os.mkdir(path)\n",
        "\n",
        "  # Save the enitire model (structure + weights)\n",
        "  #model.save(os.path.join(path,model_name+\".hdf5\"))\n",
        "\n",
        "  # Save only the weights\n",
        "  model.save_weights(os.path.join(path,model_name+\".h5\"))\n",
        "\n",
        "  # Save the structure only\n",
        "  #model_json = model.to_json()\n",
        "  #with open(os.path.join(path,model_name+\".json\"), \"w\") as json_file:\n",
        "  #    json_file.write(model_json)\n",
        "    \n",
        "  model_size = get_model_size(model_name=model_name)\n",
        "\n",
        "  # Save model history\n",
        "  with open(os.path.join(\"models\",model_name+\"_train_history.json\"), \"w\") as json_file:\n",
        "      json_file.write(json.dumps(model_train_history,cls=JsonEncoder))\n",
        "\n",
        "  trainable_parameters = count_params(model.trainable_weights)\n",
        "  non_trainable_parameters = count_params(model.non_trainable_weights)\n",
        "  total_params = trainable_parameters + non_trainable_parameters\n",
        "\n",
        "  # Save model metrics\n",
        "  metrics ={\n",
        "      \"total_params\":total_params,\n",
        "      \"execution_time\":execution_time,\n",
        "      \"loss\":evaluation_results[0],\n",
        "      \"accuracy\":evaluation_results[1],\n",
        "      \"model_size\":model_size,\n",
        "      \"learning_rate\":learning_rate,\n",
        "      \"epochs\":epochs,\n",
        "      \"optimizer\":type(optimizer).__name__,\n",
        "      \"name\": model_name,\n",
        "      \"id\": int(time.time())\n",
        "  }\n",
        "\n",
        "  with open(os.path.join(\"models\",model.name+\"_metrics.json\"), \"w\") as json_file:\n",
        "      json_file.write(json.dumps(metrics,cls=JsonEncoder))\n",
        "\n",
        "def get_model_size(path=\"models\",model_name=\"model01\"):\n",
        "  model_size = os.stat(os.path.join(path,model_name+\".hdf5\")).st_size\n",
        "  return model_size\n",
        "\n",
        "def evaluate_model(model,test_data, training_results,execution_time, learning_rate, epochs, \n",
        "                   optimizer,save=True, \n",
        "                   loss_metrics=[\"loss\",\"val_loss\"],\n",
        "                   acc_metrics=[\"accuracy\",\"val_accuracy\"]):\n",
        "    \n",
        "  # Get the model train history\n",
        "  model_train_history = training_results.history\n",
        "  # Get the number of epochs the training was run for\n",
        "  num_epochs = len(model_train_history[loss_metrics[0]])\n",
        "\n",
        "  # Plot training results\n",
        "  fig = plt.figure(figsize=(15,5))\n",
        "  axs = fig.add_subplot(1,2,1)\n",
        "  axs.set_title('Loss')\n",
        "  # Plot all metrics\n",
        "  for metric in loss_metrics:\n",
        "      axs.plot(np.arange(0, num_epochs), model_train_history[metric], label=metric)\n",
        "  axs.legend()\n",
        "  \n",
        "  axs = fig.add_subplot(1,2,2)\n",
        "  axs.set_title('Accuracy')\n",
        "  # Plot all metrics\n",
        "  for metric in acc_metrics:\n",
        "      axs.plot(np.arange(0, num_epochs), model_train_history[metric], label=metric)\n",
        "  axs.legend()\n",
        "\n",
        "  plt.show()\n",
        "  \n",
        "  # Evaluate on test data\n",
        "  evaluation_results = model.evaluate(test_data, return_dict=True)\n",
        "  print(evaluation_results)\n",
        "\n",
        "  evaluation_results = [evaluation_results[loss_metrics[0]], evaluation_results[acc_metrics[0]]]\n",
        "  \n",
        "  if save:\n",
        "      # Save model\n",
        "      save_model(model,training_results,execution_time, learning_rate, epochs, optimizer, evaluation_results)\n",
        "  \n",
        "  return evaluation_results"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBj_9MC2l8o_"
      },
      "source": [
        "# Get Top K answers\n",
        "def get_top_K_answers(k):\n",
        "    answers = pd.read_csv(\"/content/data/big2/answers.csv\", index_col=0)\n",
        "    answers = answers.iloc[:k]\n",
        "    return answers"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKnRAy5WHxkf"
      },
      "source": [
        "# Function to parse data features\n",
        "def _parse_features_function(example):\n",
        "    # Parse the input tf.train.Example proto using the dictionary above.\n",
        "    tf_records_features = {\n",
        "        'image_raw': tf.io.FixedLenFeature([], tf.string), \n",
        "        'question' : tf.io.FixedLenFeature([], tf.string),\n",
        "        'input_ids': tf.io.FixedLenFeature([], tf.string),\n",
        "        'token_type_ids': tf.io.FixedLenFeature([], tf.string),\n",
        "        'attention_mask': tf.io.FixedLenFeature([], tf.string), \n",
        "        'answer': tf.io.FixedLenFeature([], tf.int64)\n",
        "    }\n",
        "    return tf.io.parse_single_example(example, tf_records_features)\n",
        "\n",
        "\n",
        "# Filter if answer is no\n",
        "def filter_fn(x):\n",
        "    return x['answer'] < k\n",
        "\n",
        "\n",
        "# Read image and resize it\n",
        "def read_and_decode(img):\n",
        "    img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
        "    img = tf.cast(img, tf.float32)/255.0\n",
        "    return img\n",
        "\n",
        "\n",
        "# Structure the data for training\n",
        "def structure_data(data):\n",
        "    image = data['image_raw']\n",
        "    image = read_and_decode(image)\n",
        "    \n",
        "    input_ids = tf.io.decode_raw(data['input_ids'], tf.int32)\n",
        "    attention_mask = tf.io.decode_raw(data['attention_mask'], tf.int32)\n",
        "    token_type_ids = tf.io.decode_raw(data['token_type_ids'], tf.int32)\n",
        "    \n",
        "    answer = data['answer']\n",
        "\n",
        "    return ((image, (input_ids, token_type_ids, attention_mask)), answer)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOEndUuiaz7u"
      },
      "source": [
        "### Important Variables and Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG29KGghUgqZ"
      },
      "source": [
        "# Constants\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# Pipeline variables\n",
        "k = 10\n",
        "batch_size = 32\n",
        "train_buffer_size = 32\n",
        "val_buffer_size = 32\n",
        "prefetch = AUTOTUNE"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR7pciUW5__z"
      },
      "source": [
        "### Get Top Answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTFiNYkr6APs"
      },
      "source": [
        "top_answers = get_top_K_answers(k)\n",
        "TOP_ANSWERS = tf.constant(top_answers)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPWyyDZ90yFT"
      },
      "source": [
        "### Build Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbEY61HinbFk"
      },
      "source": [
        "# ############## #\n",
        "# # Train data # #\n",
        "# ############## #\n",
        "tfrecords_pattern_path = \"/content/data/big2/train2014_tf/vaq_raw_train2014_*-of-*.records\"\n",
        "train_files = tf.io.matching_files(tfrecords_pattern_path)\n",
        "train_files = tf.random.shuffle(train_files)\n",
        "train_shards = tf.data.Dataset.from_tensor_slices(train_files)\n",
        "\n",
        "train = train_shards.interleave(tf.data.TFRecordDataset)\n",
        "train = train.map(_parse_features_function, num_parallel_calls=AUTOTUNE)\n",
        "train = train.filter(filter_fn)\n",
        "train = train.map(structure_data, num_parallel_calls=AUTOTUNE)\n",
        "#train = train.shuffle(buffer_size=train_buffer_size)\n",
        "train = train.batch(batch_size)\n",
        "#train = train.cache().prefetch(prefetch)\n",
        "\n",
        "# ################### #\n",
        "# # Validation data # #\n",
        "# ################### #\n",
        "tfrecords_pattern_path = \"/content/data/big2/val2014_tf/vaq_raw_val2014_*-of-*.records\"\n",
        "val_files = tf.io.matching_files(tfrecords_pattern_path)\n",
        "val_files = tf.random.shuffle(val_files)\n",
        "val_shards = tf.data.Dataset.from_tensor_slices(val_files)\n",
        "\n",
        "valid = val_shards.interleave(tf.data.TFRecordDataset)\n",
        "valid = valid.map(_parse_features_function, num_parallel_calls=AUTOTUNE)\n",
        "valid = valid.filter(filter_fn)\n",
        "valid = valid.map(structure_data, num_parallel_calls=AUTOTUNE)\n",
        "#valid = valid.shuffle(buffer_size=val_buffer_size)\n",
        "valid = valid.batch(batch_size)\n",
        "#valid = valid.cache().prefetch(prefetch)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2QaSsOR6G6b"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRj6Qk9dzB69"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_phW9OwF_RwC"
      },
      "source": [
        "def build_vqa_model(image_height, image_width, num_channels, num_classes):\n",
        "    # Handle to pretrained model (Use a different model here)\n",
        "    input_shape=[image_height, image_width, num_channels]\n",
        "    resnet = keras.applications.VGG19(\n",
        "        include_top=False, \n",
        "        weights='imagenet', \n",
        "        input_shape=input_shape\n",
        "    )\n",
        "    resnet.trainable = False\n",
        "    image_hidden_states = layers.Flatten()(resnet.output)\n",
        "    image_hs = layers.Lambda(lambda x: K.l2_normalize(x,axis=1))(image_hidden_states)\n",
        "\n",
        "    input_ids = layers.Input(shape=(24,), dtype=tf.int32)\n",
        "    token_type_ids = layers.Input(shape=(24,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(24,), dtype=tf.int32)\n",
        "    bert = TFBertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
        "    bert.trainable = False\n",
        "    question = bert(\n",
        "        input_ids, \n",
        "        token_type_ids=token_type_ids, \n",
        "        attention_mask=attention_mask\n",
        "    )\n",
        "    question_hs = layers.Flatten()(question[1])\n",
        "    #question_hs = layers.Lambda(lambda x: K.l2_normalize(x,axis=1))(question_hs)\n",
        "\n",
        "    cross_hs = layers.concatenate([image_hs, question_hs])\n",
        "\n",
        "    x = layers.Dense(1024, 'relu')(cross_hs)\n",
        "\n",
        "    output = layers.Dense(units=num_classes)(x)\n",
        "\n",
        "    model = Model(inputs=[resnet.input, (input_ids, token_type_ids, attention_mask)], outputs=output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHRYgNHP1X4w",
        "outputId": "fbf3e5e4-1230-4e94-e3da-b0f80549fc5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256,
          "referenced_widgets": [
            "87f53882112140bdbe11bfe7ad42b0d5",
            "69c212ed44ca4c478563d25d61db064c",
            "642a2970deb84a8cbd084e854c809756",
            "1f06fa3dc7fb4b7f88d14457c7a2759c",
            "1f155ed3ac0f4558b8e567b2ffaec039",
            "29ff2e4a3565429e909f40a75b9c714a",
            "dc264f53501a4d7a82777c61551b54d8",
            "d2f91b44bb1744aea1e16db7dde48cd7",
            "beabae3a77dd4a4883c2dc7a7a244f83",
            "49578736331b4f038e79bfb037a7ccc7",
            "cabfc24290ae49b694039dea2acd48a4",
            "649e46e9b0724f47af98e27c0c527e12",
            "530c7312a0804423be223997a53a933a",
            "a4db792a7f4c4ff69b48578f76da7db2",
            "41f672b0f28b432d9df5cb17dbc92d78",
            "b6604b4a078d40a3b70dc0c4c838b311"
          ]
        }
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "model = build_vqa_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, k)\n",
        "\n",
        "# Optimizer\n",
        "learning_rate = 0.0001\n",
        "optimizer = optimizers.Adam(lr=learning_rate)\n",
        "\n",
        "# Loss\n",
        "loss = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Compile\n",
        "model.compile(\n",
        "    loss=loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87f53882112140bdbe11bfe7ad42b0d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "beabae3a77dd4a4883c2dc7a7a244f83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoMKbG_g6Hij"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKTg-OVr1mFP",
        "outputId": "0c88c046-d7e2-4573-a959-92cb8d302443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train model\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/Practicum2Data/vqa_model.h5')\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "training_results = model.fit(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    callbacks = keras.callbacks.ModelCheckpoint( \n",
        "        filepath='/content/drive/My Drive/Practicum2Data/vqa_model.h5', \n",
        "        monitor='val_accuracy', \n",
        "        save_best_only=True, \n",
        "        save_weights_only=True\n",
        "    ),\n",
        "    class_weight = (top_answers.sum()/top_answers).reset_index().frequency.to_dict(),\n",
        "    epochs=epochs, \n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Training execution time (mins)\",execution_time)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Epoch 1/10\n",
            "7138/7138 [==============================] - 832s 117ms/step - loss: 10.2229 - accuracy: 0.5261 - val_loss: 0.8570 - val_accuracy: 0.5081\n",
            "Epoch 2/10\n",
            "7138/7138 [==============================] - 830s 116ms/step - loss: 10.1875 - accuracy: 0.5275 - val_loss: 0.8576 - val_accuracy: 0.5080\n",
            "Epoch 3/10\n",
            "7138/7138 [==============================] - 829s 116ms/step - loss: 10.1333 - accuracy: 0.5292 - val_loss: 0.8569 - val_accuracy: 0.5095\n",
            "Epoch 4/10\n",
            "7138/7138 [==============================] - 826s 116ms/step - loss: 10.1098 - accuracy: 0.5290 - val_loss: 0.8600 - val_accuracy: 0.5084\n",
            "Epoch 5/10\n",
            "7138/7138 [==============================] - 827s 116ms/step - loss: 10.0782 - accuracy: 0.5300 - val_loss: 0.8574 - val_accuracy: 0.5092\n",
            "Epoch 6/10\n",
            "7138/7138 [==============================] - 829s 116ms/step - loss: 10.0421 - accuracy: 0.5295 - val_loss: 0.8569 - val_accuracy: 0.5089\n",
            "Epoch 7/10\n",
            "7138/7138 [==============================] - 823s 115ms/step - loss: 10.0298 - accuracy: 0.5305 - val_loss: 0.8609 - val_accuracy: 0.5073\n",
            "Epoch 8/10\n",
            "7138/7138 [==============================] - 824s 115ms/step - loss: 9.9869 - accuracy: 0.5313 - val_loss: 0.8588 - val_accuracy: 0.5090\n",
            "Epoch 9/10\n",
            "7138/7138 [==============================] - 823s 115ms/step - loss: 9.9556 - accuracy: 0.5313 - val_loss: 0.8598 - val_accuracy: 0.5079\n",
            "Epoch 10/10\n",
            "7138/7138 [==============================] - 822s 115ms/step - loss: 9.9412 - accuracy: 0.5315 - val_loss: 0.8579 - val_accuracy: 0.5094\n",
            "Training execution time (mins) 138.07061746120453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n-v79TaNqOy"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-jMYcRlMXXh",
        "outputId": "8d1c0ce5-6b18-4f31-9b88-63567cc9e836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        }
      },
      "source": [
        "evaluate_model(\n",
        "    model, \n",
        "    valid, \n",
        "    training_results, \n",
        "    execution_time, \n",
        "    learning_rate, \n",
        "    batch_size, \n",
        "    epochs, \n",
        "    optimizers\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3441/3441 [==============================] - 262s 76ms/step - loss: 0.8579 - accuracy: 0.5094\n",
            "{'loss': 0.8579386472702026, 'accuracy': 0.509381890296936}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-2d0ed6a4f74e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-27-438e8a09a9c4>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_data, training_results, execution_time, learning_rate, epochs, optimizer, save, loss_metrics, acc_metrics)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m       \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexecution_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mevaluation_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-438e8a09a9c4>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, training_results, execution_time, learning_rate, epochs, optimizer, evaluation_results, path)\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;31m#    json_file.write(model_json)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mmodel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;31m# Save model history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-438e8a09a9c4>\u001b[0m in \u001b[0;36mget_model_size\u001b[0;34m(path, model_name)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model01\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m   \u001b[0mmodel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/functional_1.hdf5'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0PPmp624ZSp"
      },
      "source": [
        "model.save_weights(\"weights.h5\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBYp1yE_5iEc",
        "outputId": "9fc5faa5-6122-434d-da40-8fd5966fc723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "model.save(\"model.hdf5\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4a66770c061f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \"\"\"\n\u001b[1;32m   1978\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1979\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m   def save_weights(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    129\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    130\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 131\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    132\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mmodel_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m   metadata = dict(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   1276\u001b[0m         \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m     \u001b[0mlayer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inbound_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    248\u001b[0m         return serialize_keras_class_and_config(\n\u001b[1;32m    249\u001b[0m             name, {_LAYER_UNDEFINED_CONFIG_KEY: True})\n\u001b[0;32m--> 250\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0mserialization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m       \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_SKIP_FAILED_SERIALIZATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2231\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzU7EbMh6Cr_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}