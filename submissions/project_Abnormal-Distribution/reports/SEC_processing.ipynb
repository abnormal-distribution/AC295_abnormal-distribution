{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SEC_processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7G511kTOAfs"
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from time import time\n",
        "\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwgzR7_DOKK-",
        "outputId": "be1cd0b8-b67c-4a18-c805-d285016427ed"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsxb-i6XAsaM"
      },
      "source": [
        "def get_documents(text):\n",
        "    \"\"\"\n",
        "    Extract the documents from the text\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    text : str\n",
        "        The text with the document strings inside\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    extracted_docs : list of str\n",
        "        The document strings found in `text`\n",
        "    \"\"\"\n",
        "    extracted_docs =[]\n",
        "\n",
        "    # Write Regexes\n",
        "    doc_start_pattern = re.compile(r'<DOCUMENT>')\n",
        "    doc_end_pattern = re.compile(r'</DOCUMENT>')\n",
        "\n",
        "    # Create 2 lists with the span indices for each regex\n",
        "    doc_start_is = [x.end() for x in doc_start_pattern.finditer(text)]\n",
        "    doc_end_is = [x.start() for x in doc_end_pattern.finditer(text)]\n",
        "\n",
        "    for doc_start_i, doc_end_i in zip(doc_start_is, doc_end_is):\n",
        "        extracted_docs.append(text[doc_start_i:doc_end_i])\n",
        "    \n",
        "    return extracted_docs\n",
        "    \n",
        "\n",
        "def get_doc_type(doc):\n",
        "  \n",
        "  type_pattern = re.compile(r'<TYPE>[^\\n]+')\n",
        "  doc_type = type_pattern.search(doc).group(0)[len('<TYPE>'):].lower()\n",
        "  return doc_type"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7GAUruHODU4"
      },
      "source": [
        "dir_10Q = '/content/drive/MyDrive/abnormal-distribution-project-data/10-Q/'\n",
        "dir_10K = '/content/drive/MyDrive/abnormal-distribution-project-data/10-K/'\n",
        "\n",
        "files_10K = os.listdir('/content/drive/MyDrive/abnormal-distribution-project-data/10-K/')\n",
        "files_10Q = os.listdir('/content/drive/MyDrive/abnormal-distribution-project-data/10-K/')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeFE_AzkA7M5"
      },
      "source": [
        "regex_10k = re.compile(r'(>Item(\\s|&#160;|&nbsp;)(1A|1B|7A|7|8)\\.{0,1})|(ITEM\\s(1A|1B|7A|7|8))')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "8yFoV-0ZAfQP",
        "outputId": "ed0a9fdc-ff90-496a-dca4-9e7d48c69261"
      },
      "source": [
        "start = time()\n",
        "\n",
        "dict_10k = {}\n",
        "\n",
        "errors = []\n",
        "\n",
        "for i, filename in enumerate(files_10K):\n",
        "\n",
        "  if i%100 == 0:\n",
        "    print(i)\n",
        "    print(\"Working on: {}, time so far: {}\".format(filename, time()-start))\n",
        "\n",
        "  #if int(filename.split('-')[3]) <= 2010:\n",
        "\n",
        "   # continue\n",
        "\n",
        "  # open 10-k text file\n",
        "  with open(dir_10K + filename) as f:\n",
        "    docs = f.read()\n",
        "    # Find 10-k document portion in text file\n",
        "    docs = get_documents(docs)\n",
        "    for doc in docs:\n",
        "      if get_doc_type(doc) == '10-k':\n",
        "        break\n",
        "\n",
        "  # Regex for finding sections 1a, 7 and 9\n",
        "  matches = regex_10k.finditer(doc)\n",
        "\n",
        "  # try/catch statement will fail if sections 1a, 7, and 9 aren't in the doc\n",
        "  try:\n",
        "    \n",
        "    # Positional df with starting and ending indices for each section\n",
        "    pos_df = pd.DataFrame([(match.group(), \n",
        "                              match.start(), \n",
        "                              match.end()) for match in matches])\n",
        "\n",
        "    pos_df.columns = ['item', 'start', 'end']\n",
        "    pos_df['item'] = pos_df.item.str.lower()\n",
        "    pos_df['item'] = pos_df.item.str.replace(' ','')\n",
        "\n",
        "    # Get rid of unnesesary charcters from the dataframe\n",
        "    pos_df.replace('&#160;',' ',regex=True,inplace=True)\n",
        "    pos_df.replace('&nbsp;',' ',regex=True,inplace=True)\n",
        "    pos_df.replace(' ','',regex=True,inplace=True)\n",
        "    pos_df.replace('\\.','',regex=True,inplace=True)\n",
        "    pos_df.replace('>','',regex=True,inplace=True)\n",
        "\n",
        "    # Drop duplicates\n",
        "    pos_df = pos_df.sort_values('start', \n",
        "                                ascending=True).drop_duplicates(subset=['item'], \n",
        "                                                                keep='last')\n",
        "                                \n",
        "    pos_df.set_index('item', inplace=True)\n",
        "\n",
        "\n",
        "                                \n",
        "    # Get Item 1a\n",
        "    item_1a = doc[pos_df['start'].loc['item1a']:pos_df['start'].loc['item1b']]\n",
        "    item_1a = BeautifulSoup(item_1a, 'lxml').get_text(\"\\n\\n\")\n",
        "\n",
        "    # Get Item 7\n",
        "    item_7 = doc[pos_df['start'].loc['item7']:pos_df['start'].loc['item7a']]\n",
        "    item_7 = BeautifulSoup(item_7, 'lxml').get_text(\"\\n\\n\")\n",
        "\n",
        "    # Get Item 7a\n",
        "    item_7a = doc[pos_df['start'].loc['item7a']:pos_df['start'].loc['item8']]\n",
        "    item_7a = BeautifulSoup(item_7a, 'lxml').get_text(\"\\n\\n\")\n",
        "\n",
        "    # Create dictionaries with each parsed document split by sections\n",
        "    sub_dict = {}\n",
        "\n",
        "    sub_dict['1a'] = item_1a\n",
        "    sub_dict['7'] = item_7\n",
        "    sub_dict['7a'] = item_7a\n",
        "\n",
        "    dict_10k[filename] = sub_dict.copy()\n",
        "\n",
        "  except:\n",
        "\n",
        "    errors.append(filename)\n",
        "\n",
        "\n",
        "print(time()-start)\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Working on: WEC-10-K-2005-03-04.txt, time so far: 0.0067081451416015625\n",
            "100\n",
            "Working on: WDC-10-K-2004-09-14.txt, time so far: 239.89579033851624\n",
            "200\n",
            "Working on: WLTW-10-K-2013-02-28.txt, time so far: 454.9840703010559\n",
            "300\n",
            "Working on: YUM-10-K-2009-02-23.txt, time so far: 623.0250127315521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-d8685334ad0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_10K\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k06bEh3HQreL",
        "outputId": "39ea1f3e-e132-4e59-f6dd-85660b5aebcc"
      },
      "source": [
        "dict_10k.keys()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['WFC-10-K-2020-02-27.txt', 'WFC-10-K-2019-02-27.txt'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VTbTg_MZ6KC",
        "outputId": "7eafdf13-500f-45d7-b20e-3a7c8d54cdc3"
      },
      "source": [
        "\n",
        "### Our goal is though to remove html tags and see the content\n",
        "### Method get_text() is what we need, \\n\\n is optional, I just added this to read text \n",
        "### more cleanly, it's basically new line character between sections. \n",
        "print(item_1a.get_text(\"\\n\\n\")[0:1500])"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">Item 1A.\n",
            "\n",
            "Risk Factors\n",
            "\n",
            "Please carefully consider the following discussion of significant factors, events, and uncertainties that make an investment in our securities risky. The events and consequences discussed in these risk factors could, in circumstances we may or may not be able to accurately predict, recognize, or control, have a material adverse effect on our business, growth, reputation, prospects, financial condition, operating results (including components of our financial results), cash flows, liquidity, and stock price. These risk factors do not identify all risks that we face; our operations could also be affected by factors, events, or uncertainties that are not presently known to us or that we currently do not consider to present significant risks to our operations. In addition, the global economic climate amplifies many of these risks.\n",
            "\n",
            "We Face Intense Competition\n",
            "\n",
            "Our businesses are rapidly evolving and intensely competitive, and we have many competitors across geographies, including cross-border competition, and in different industries, including physical, e-commerce, and omnichannel retail, e-commerce services, web and infrastructure computing services, electronic devices, digital content, advertising, grocery, and transportation and logistics services. Some of our current and potential competitors have greater resources, longer histories, more customers, and/or greater brand recognition, particularly with our newly-launched products and services and in our\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzhgEtftdqll",
        "outputId": "3f00e424-79f7-4578-f3d4-03ce52b86ed3"
      },
      "source": [
        "print(item_7.get_text(\"\\n\\n\")[0:1500])"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">Item 7.\n",
            "\n",
            "Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
            "\n",
            "Forward-Looking Statements\n",
            "\n",
            "This Annual Report on Form 10-K includes forward-looking statements within the meaning of the Private Securities Litigation Reform Act of 1995. All statements other than statements of historical fact, including statements regarding guidance, industry prospects, or future results of operations or financial position, made in this Annual Report on Form 10-K are forward-looking. We use words such as anticipates, believes, expects, future, intends, and similar expressions to identify forward-looking statements. Forward-looking statements reflect management’s current expectations and are inherently uncertain. Actual results could differ materially for a variety of reasons, including, among others, fluctuations in foreign exchange rates, changes in global economic conditions and customer spending, world events, the rate of growth of the Internet, online commerce, and cloud services, the amount that Amazon.com invests in new business opportunities and the timing of those investments, the mix of products and services sold to customers, the mix of net sales derived from products as compared with services, the extent to which we owe income or other taxes, competition, management of growth, potential fluctuations in operating results, international growth and expansion, the outcomes of claims, litigation, government investigations, and other proceedings, fulfillmen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM9wQQOXd0HY",
        "outputId": "4dd08cc6-fb2a-4a45-ff54-805b0c6d129c"
      },
      "source": [
        "print(item_7a.get_text(\"\\n\\n\")[0:1500])"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">Item 7A.\n",
            "\n",
            "Quantitative and Qualitative Disclosures About Market Risk\n",
            "\n",
            "We are exposed to market risk for the effect of interest rate changes, foreign currency fluctuations, and changes in the market values of our investments. Information relating to quantitative and qualitative disclosures about market risk is set forth below and in Item 7 of Part II, “Management’s Discussion and Analysis of Financial Condition and Results of Operations — Liquidity and Capital Resources.”\n",
            "\n",
            "Interest Rate Risk\n",
            "\n",
            "Our exposure to market risk for changes in interest rates relates primarily to our investment portfolio and our long-term debt. Our long-term debt is carried at amortized cost and fluctuations in interest rates do not impact our consolidated financial statements. However, the fair value of our debt, which pays interest at a fixed rate, will generally fluctuate with movements of interest rates, increasing in periods of declining rates of interest and declining in periods of increasing rates of interest. We generally invest our excess cash in AAA-rated money market funds and investment grade short- to intermediate-term fixed income securities. Fixed income securities may have their fair market value adversely affected due to a rise in interest rates, and we may suffer losses in principal if forced to sell securities that have declined in market value due to changes in interest rates.\n",
            "\n",
            "The following table provides information about our cash equivalents and marketable fixed income securities\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}