{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4x5c6Arur3q",
        "outputId": "9e42747c-233c-4157-942d-8ce9970ed3ce"
      },
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 13.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 26.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=130abb23bae12f961a654db40beb00659362483a06448eb4c07734c44274f480\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n",
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/38/0c24dce24767386123d528d27109024220db0e7a04467b658d587695241a/datasets-1.1.3-py3-none-any.whl (153kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 13.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.18.5)\n",
            "Collecting pyarrow>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
            "\u001b[K     |████████████████████████████████| 17.7MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, pyarrow, datasets\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed datasets-1.1.3 pyarrow-2.0.0 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5oy4jDq0BgA"
      },
      "source": [
        "## Notebook to fine tune BERT through language modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKVwHzQg3xWZ"
      },
      "source": [
        "import pickle\n",
        "import transformers\n",
        "import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1_Z6ov-vSF5",
        "outputId": "50f55560-8ba7-48ba-cd9a-b8f7d155baad"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKYyoE3731Od"
      },
      "source": [
        "tx = pickle.load(open('/content/drive/MyDrive/abnormal-distribution-project-data/lean/valid.p','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rBDNg2R644V",
        "outputId": "d677b5a0-aff2-4373-92ff-32dff39e678e"
      },
      "source": [
        "tx.sample(frac=0.03).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13655, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS-3sVWi4CW1"
      },
      "source": [
        "with open('/content/drive/MyDrive/abnormal-distribution-project-data/lean/valid.txt', 'w') as f:\n",
        "    for item in tx.sample(frac=0.035).text.to_list():\n",
        "        f.write(\"%s\\n\" % item)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fehamjgP7FZO",
        "outputId": "19541efd-a16b-48f9-884e-f6fa6ad62083"
      },
      "source": [
        "!python /content/drive/MyDrive/abnormal-distribution-project-data/lean/run_mlm.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 13:52:15.041744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "usage: run_mlm.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH]\n",
            "                  [--model_type MODEL_TYPE] [--config_name CONFIG_NAME]\n",
            "                  [--tokenizer_name TOKENIZER_NAME] [--cache_dir CACHE_DIR]\n",
            "                  [--no_use_fast_tokenizer] [--dataset_name DATASET_NAME]\n",
            "                  [--dataset_config_name DATASET_CONFIG_NAME]\n",
            "                  [--train_file TRAIN_FILE]\n",
            "                  [--validation_file VALIDATION_FILE] [--overwrite_cache]\n",
            "                  [--max_seq_length MAX_SEQ_LENGTH]\n",
            "                  [--preprocessing_num_workers PREPROCESSING_NUM_WORKERS]\n",
            "                  [--mlm_probability MLM_PROBABILITY] [--line_by_line]\n",
            "                  [--pad_to_max_length] --output_dir OUTPUT_DIR\n",
            "                  [--overwrite_output_dir] [--do_train] [--do_eval]\n",
            "                  [--do_predict]\n",
            "                  [--evaluation_strategy {EvaluationStrategy.NO,EvaluationStrategy.STEPS,EvaluationStrategy.EPOCH}]\n",
            "                  [--prediction_loss_only]\n",
            "                  [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
            "                  [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
            "                  [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
            "                  [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
            "                  [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                  [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]\n",
            "                  [--learning_rate LEARNING_RATE]\n",
            "                  [--weight_decay WEIGHT_DECAY] [--adam_beta1 ADAM_BETA1]\n",
            "                  [--adam_beta2 ADAM_BETA2] [--adam_epsilon ADAM_EPSILON]\n",
            "                  [--max_grad_norm MAX_GRAD_NORM]\n",
            "                  [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                  [--max_steps MAX_STEPS] [--warmup_steps WARMUP_STEPS]\n",
            "                  [--logging_dir LOGGING_DIR] [--logging_first_step]\n",
            "                  [--logging_steps LOGGING_STEPS] [--save_steps SAVE_STEPS]\n",
            "                  [--save_total_limit SAVE_TOTAL_LIMIT] [--no_cuda]\n",
            "                  [--seed SEED] [--fp16] [--fp16_opt_level FP16_OPT_LEVEL]\n",
            "                  [--local_rank LOCAL_RANK] [--tpu_num_cores TPU_NUM_CORES]\n",
            "                  [--tpu_metrics_debug] [--debug] [--dataloader_drop_last]\n",
            "                  [--eval_steps EVAL_STEPS]\n",
            "                  [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
            "                  [--past_index PAST_INDEX] [--run_name RUN_NAME]\n",
            "                  [--disable_tqdm DISABLE_TQDM] [--no_remove_unused_columns]\n",
            "                  [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
            "                  [--load_best_model_at_end]\n",
            "                  [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
            "                  [--greater_is_better GREATER_IS_BETTER]\n",
            "run_mlm.py: error: the following arguments are required: --output_dir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXROXE8Jv_xp",
        "outputId": "f2f5acd3-ec1b-4dc4-cf53-959d9bd96057"
      },
      "source": [
        "!python /content/drive/MyDrive/abnormal-distribution-project-data/lean/run_mlm.py \\\n",
        "--model_name_or_path bert-base-uncased \\\n",
        "--train_file /content/drive/MyDrive/abnormal-distribution-project-data/lean/train.txt \\\n",
        "--validation_file /content/drive/MyDrive/abnormal-distribution-project-data/lean/valid.txt \\\n",
        "--output_dir /content/drive/MyDrive/abnormal-distribution-project-data/lean/models \\\n",
        "--save_steps 5000 \\\n",
        "--learning_rate 2e-5 \\\n",
        "--logging_dir /content/drive/MyDrive/abnormal-distribution-project-data/lean/logs \\\n",
        "--do_train \\\n",
        "--do_eval \\\n",
        "--line_by_line \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 13:53:01.992846: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "12/10/2020 13:53:03 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "12/10/2020 13:53:03 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='/content/drive/MyDrive/abnormal-distribution-project-data/lean/models', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='/content/drive/MyDrive/abnormal-distribution-project-data/lean/logs', logging_first_step=False, logging_steps=500, save_steps=5000, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='/content/drive/MyDrive/abnormal-distribution-project-data/lean/models', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Using custom data configuration default\n",
            "Downloading and preparing dataset text/default-4b9712f2cd4777ec (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-4b9712f2cd4777ec/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab...\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-4b9712f2cd4777ec/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab. Subsequent calls will reuse this data.\n",
            "[INFO|configuration_utils.py:411] 2020-12-10 13:53:08,450 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\n",
            "[INFO|configuration_utils.py:447] 2020-12-10 13:53:08,450 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:411] 2020-12-10 13:53:09,027 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\n",
            "[INFO|configuration_utils.py:447] 2020-12-10 13:53:09,027 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1768] 2020-12-10 13:53:10,145 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "[INFO|tokenization_utils_base.py:1768] 2020-12-10 13:53:10,145 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "[INFO|modeling_utils.py:940] 2020-12-10 13:53:10,751 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "[WARNING|modeling_utils.py:1048] 2020-12-10 13:53:20,510 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[INFO|modeling_utils.py:1065] 2020-12-10 13:53:20,510 >> All the weights of BertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
            "100% 351/351 [01:14<00:00,  4.72ba/s]\n",
            "100% 17/17 [00:02<00:00,  6.68ba/s]\n",
            "[INFO|trainer.py:357] 2020-12-10 13:54:43,613 >> The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: special_tokens_mask.\n",
            "[INFO|trainer.py:357] 2020-12-10 13:54:43,614 >> The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: special_tokens_mask.\n",
            "[INFO|trainer.py:662] 2020-12-10 13:54:43,618 >> ***** Running training *****\n",
            "[INFO|trainer.py:663] 2020-12-10 13:54:43,618 >>   Num examples = 336218\n",
            "[INFO|trainer.py:664] 2020-12-10 13:54:43,618 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:665] 2020-12-10 13:54:43,618 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:666] 2020-12-10 13:54:43,618 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer.py:667] 2020-12-10 13:54:43,618 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:668] 2020-12-10 13:54:43,619 >>   Total optimization steps = 126084\n",
            "{'loss': 2.656969482421875, 'learning_rate': 1.9920687795437963e-05, 'epoch': 0.011896830684305701}\n",
            "{'loss': 2.252690673828125, 'learning_rate': 1.9841375590875928e-05, 'epoch': 0.023793661368611402}\n",
            "{'loss': 2.1071455078125, 'learning_rate': 1.976206338631389e-05, 'epoch': 0.035690492052917105}\n",
            "{'loss': 2.060102294921875, 'learning_rate': 1.968275118175185e-05, 'epoch': 0.047587322737222805}\n",
            "{'loss': 1.98281689453125, 'learning_rate': 1.9603438977189812e-05, 'epoch': 0.059484153421528504}\n",
            "{'loss': 1.944635498046875, 'learning_rate': 1.9524126772627773e-05, 'epoch': 0.07138098410583421}\n",
            "{'loss': 1.923089111328125, 'learning_rate': 1.9444814568065735e-05, 'epoch': 0.0832778147901399}\n",
            "{'loss': 1.917810791015625, 'learning_rate': 1.9365502363503696e-05, 'epoch': 0.09517464547444561}\n",
            "{'loss': 1.8334464111328126, 'learning_rate': 1.928619015894166e-05, 'epoch': 0.1070714761587513}\n",
            "{'loss': 1.87287451171875, 'learning_rate': 1.9206877954379623e-05, 'epoch': 0.11896830684305701}\n",
            "  4% 5000/126084 [15:56<7:01:46,  4.78it/s][INFO|trainer.py:1162] 2020-12-10 14:10:40,434 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-5000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 14:10:40,442 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-5000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 14:10:42,372 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-5000/pytorch_model.bin\n",
            "{'loss': 1.8504390869140626, 'learning_rate': 1.9127565749817584e-05, 'epoch': 0.1308651375273627}\n",
            "{'loss': 1.78317236328125, 'learning_rate': 1.9048253545255545e-05, 'epoch': 0.14276196821166842}\n",
            "{'loss': 1.73906494140625, 'learning_rate': 1.8968941340693507e-05, 'epoch': 0.15465879889597411}\n",
            "{'loss': 1.786865234375, 'learning_rate': 1.8889629136131468e-05, 'epoch': 0.1665556295802798}\n",
            "{'loss': 1.7356744384765626, 'learning_rate': 1.8810316931569433e-05, 'epoch': 0.17845246026458553}\n",
            "{'loss': 1.7382877197265625, 'learning_rate': 1.8731004727007394e-05, 'epoch': 0.19034929094889122}\n",
            "{'loss': 1.727135009765625, 'learning_rate': 1.8651692522445356e-05, 'epoch': 0.2022461216331969}\n",
            "{'loss': 1.7055740966796875, 'learning_rate': 1.8572380317883317e-05, 'epoch': 0.2141429523175026}\n",
            "{'loss': 1.6973017578125, 'learning_rate': 1.849306811332128e-05, 'epoch': 0.22603978300180833}\n",
            "{'loss': 1.7051025390625, 'learning_rate': 1.841375590875924e-05, 'epoch': 0.23793661368611402}\n",
            "  8% 10000/126084 [31:59<5:35:07,  5.77it/s][INFO|trainer.py:1162] 2020-12-10 14:26:43,245 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-10000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 14:26:43,252 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-10000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 14:26:45,466 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-10000/pytorch_model.bin\n",
            "{'loss': 1.706208740234375, 'learning_rate': 1.83344437041972e-05, 'epoch': 0.2498334443704197}\n",
            "{'loss': 1.6877242431640624, 'learning_rate': 1.8255131499635166e-05, 'epoch': 0.2617302750547254}\n",
            "{'loss': 1.6471082763671876, 'learning_rate': 1.8175819295073128e-05, 'epoch': 0.2736271057390311}\n",
            "{'loss': 1.668968017578125, 'learning_rate': 1.809650709051109e-05, 'epoch': 0.28552393642333684}\n",
            "{'loss': 1.6339552001953126, 'learning_rate': 1.801719488594905e-05, 'epoch': 0.29742076710764254}\n",
            "{'loss': 1.6669208984375, 'learning_rate': 1.7937882681387012e-05, 'epoch': 0.30931759779194823}\n",
            "{'loss': 1.679597900390625, 'learning_rate': 1.7858570476824973e-05, 'epoch': 0.3212144284762539}\n",
            "{'loss': 1.6640736083984375, 'learning_rate': 1.7779258272262938e-05, 'epoch': 0.3331112591605596}\n",
            "{'loss': 1.66512158203125, 'learning_rate': 1.76999460677009e-05, 'epoch': 0.3450080898448653}\n",
            "{'loss': 1.61974853515625, 'learning_rate': 1.762063386313886e-05, 'epoch': 0.35690492052917105}\n",
            " 12% 15000/126084 [48:05<4:34:26,  6.75it/s][INFO|trainer.py:1162] 2020-12-10 14:42:49,153 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-15000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 14:42:49,161 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-15000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 14:42:51,292 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-15000/pytorch_model.bin\n",
            "{'loss': 1.625235595703125, 'learning_rate': 1.7541321658576826e-05, 'epoch': 0.36880175121347675}\n",
            "{'loss': 1.6182486572265624, 'learning_rate': 1.7462009454014787e-05, 'epoch': 0.38069858189778244}\n",
            "{'loss': 1.631508544921875, 'learning_rate': 1.7382697249452745e-05, 'epoch': 0.39259541258208813}\n",
            "{'loss': 1.5881695556640625, 'learning_rate': 1.7303385044890707e-05, 'epoch': 0.4044922432663938}\n",
            "{'loss': 1.5903966064453126, 'learning_rate': 1.722407284032867e-05, 'epoch': 0.4163890739506995}\n",
            "{'loss': 1.5872918701171874, 'learning_rate': 1.7144760635766633e-05, 'epoch': 0.4282859046350052}\n",
            "{'loss': 1.6260030517578126, 'learning_rate': 1.7065448431204594e-05, 'epoch': 0.44018273531931096}\n",
            "{'loss': 1.5959755859375, 'learning_rate': 1.698613622664256e-05, 'epoch': 0.45207956600361665}\n",
            "{'loss': 1.5656695556640625, 'learning_rate': 1.690682402208052e-05, 'epoch': 0.46397639668792234}\n",
            "{'loss': 1.5805872802734375, 'learning_rate': 1.6827511817518482e-05, 'epoch': 0.47587322737222804}\n",
            " 16% 20000/126084 [1:04:14<5:23:21,  5.47it/s][INFO|trainer.py:1162] 2020-12-10 14:58:57,852 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-20000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 14:58:57,860 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-20000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 14:58:59,900 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-20000/pytorch_model.bin\n",
            "{'loss': 1.5462398681640626, 'learning_rate': 1.6748199612956443e-05, 'epoch': 0.48777005805653373}\n",
            "{'loss': 1.55486865234375, 'learning_rate': 1.6668887408394405e-05, 'epoch': 0.4996668887408394}\n",
            "{'loss': 1.5338389892578126, 'learning_rate': 1.6589575203832366e-05, 'epoch': 0.5115637194251451}\n",
            "{'loss': 1.559494140625, 'learning_rate': 1.651026299927033e-05, 'epoch': 0.5234605501094508}\n",
            "{'loss': 1.5462059326171875, 'learning_rate': 1.6430950794708292e-05, 'epoch': 0.5353573807937565}\n",
            "{'loss': 1.5725289306640624, 'learning_rate': 1.6351638590146254e-05, 'epoch': 0.5472542114780622}\n",
            "{'loss': 1.5593406982421876, 'learning_rate': 1.6272326385584215e-05, 'epoch': 0.559151042162368}\n",
            "{'loss': 1.573537353515625, 'learning_rate': 1.6193014181022176e-05, 'epoch': 0.5710478728466737}\n",
            "{'loss': 1.5254639892578126, 'learning_rate': 1.6113701976460138e-05, 'epoch': 0.5829447035309794}\n",
            "{'loss': 1.5233240966796875, 'learning_rate': 1.60343897718981e-05, 'epoch': 0.5948415342152851}\n",
            " 20% 25000/126084 [1:20:07<5:56:45,  4.72it/s][INFO|trainer.py:1162] 2020-12-10 15:14:50,720 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-25000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 15:14:50,728 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-25000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 15:14:52,667 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-25000/pytorch_model.bin\n",
            "{'loss': 1.561598388671875, 'learning_rate': 1.5955077567336064e-05, 'epoch': 0.6067383648995908}\n",
            "{'loss': 1.547915283203125, 'learning_rate': 1.5875765362774026e-05, 'epoch': 0.6186351955838965}\n",
            "{'loss': 1.507752197265625, 'learning_rate': 1.5796453158211987e-05, 'epoch': 0.6305320262682022}\n",
            "{'loss': 1.55414404296875, 'learning_rate': 1.571714095364995e-05, 'epoch': 0.6424288569525078}\n",
            "{'loss': 1.522035400390625, 'learning_rate': 1.563782874908791e-05, 'epoch': 0.6543256876368135}\n",
            "{'loss': 1.525219482421875, 'learning_rate': 1.555851654452587e-05, 'epoch': 0.6662225183211192}\n",
            "{'loss': 1.53696484375, 'learning_rate': 1.5479204339963836e-05, 'epoch': 0.6781193490054249}\n",
            "{'loss': 1.5254317626953124, 'learning_rate': 1.5399892135401797e-05, 'epoch': 0.6900161796897306}\n",
            "{'loss': 1.529968505859375, 'learning_rate': 1.532057993083976e-05, 'epoch': 0.7019130103740363}\n",
            "{'loss': 1.529720458984375, 'learning_rate': 1.524126772627772e-05, 'epoch': 0.7138098410583421}\n",
            " 24% 30000/126084 [1:36:05<4:56:12,  5.41it/s][INFO|trainer.py:1162] 2020-12-10 15:30:49,391 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-30000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 15:30:49,399 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-30000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 15:30:51,518 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-30000/pytorch_model.bin\n",
            "{'loss': 1.4832791748046874, 'learning_rate': 1.5161955521715683e-05, 'epoch': 0.7257066717426478}\n",
            "{'loss': 1.481874267578125, 'learning_rate': 1.5082643317153645e-05, 'epoch': 0.7376035024269535}\n",
            "{'loss': 1.5235458984375, 'learning_rate': 1.5003331112591606e-05, 'epoch': 0.7495003331112592}\n",
            "{'loss': 1.5006165771484374, 'learning_rate': 1.492401890802957e-05, 'epoch': 0.7613971637955649}\n",
            "{'loss': 1.4961583251953126, 'learning_rate': 1.484470670346753e-05, 'epoch': 0.7732939944798706}\n",
            "{'loss': 1.500308349609375, 'learning_rate': 1.4765394498905492e-05, 'epoch': 0.7851908251641763}\n",
            "{'loss': 1.5079700927734374, 'learning_rate': 1.4686082294343455e-05, 'epoch': 0.797087655848482}\n",
            "{'loss': 1.478779541015625, 'learning_rate': 1.4606770089781417e-05, 'epoch': 0.8089844865327876}\n",
            "{'loss': 1.4939951171875, 'learning_rate': 1.4527457885219378e-05, 'epoch': 0.8208813172170933}\n",
            "{'loss': 1.4694132080078126, 'learning_rate': 1.4448145680657341e-05, 'epoch': 0.832778147901399}\n",
            " 28% 35000/126084 [1:51:57<6:11:26,  4.09it/s][INFO|trainer.py:1162] 2020-12-10 15:46:40,995 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-35000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 15:46:41,002 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-35000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 15:46:43,018 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-35000/pytorch_model.bin\n",
            "{'loss': 1.50053271484375, 'learning_rate': 1.4368833476095302e-05, 'epoch': 0.8446749785857047}\n",
            "{'loss': 1.4812398681640624, 'learning_rate': 1.4289521271533264e-05, 'epoch': 0.8565718092700104}\n",
            "{'loss': 1.4363997802734374, 'learning_rate': 1.4210209066971225e-05, 'epoch': 0.8684686399543162}\n",
            "{'loss': 1.5030938720703124, 'learning_rate': 1.4130896862409188e-05, 'epoch': 0.8803654706386219}\n",
            "{'loss': 1.51168701171875, 'learning_rate': 1.405158465784715e-05, 'epoch': 0.8922623013229276}\n",
            "{'loss': 1.4984093017578124, 'learning_rate': 1.3972272453285111e-05, 'epoch': 0.9041591320072333}\n",
            "{'loss': 1.4639207763671875, 'learning_rate': 1.3892960248723076e-05, 'epoch': 0.916055962691539}\n",
            "{'loss': 1.489736328125, 'learning_rate': 1.3813648044161036e-05, 'epoch': 0.9279527933758447}\n",
            "{'loss': 1.4579862060546875, 'learning_rate': 1.3734335839598997e-05, 'epoch': 0.9398496240601504}\n",
            "{'loss': 1.4757431640625, 'learning_rate': 1.3655023635036962e-05, 'epoch': 0.9517464547444561}\n",
            " 32% 40000/126084 [2:07:47<4:02:01,  5.93it/s][INFO|trainer.py:1162] 2020-12-10 16:02:31,141 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-40000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 16:02:31,148 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-40000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 16:02:33,352 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-40000/pytorch_model.bin\n",
            "{'loss': 1.460873291015625, 'learning_rate': 1.3575711430474923e-05, 'epoch': 0.9636432854287618}\n",
            "{'loss': 1.519879638671875, 'learning_rate': 1.3496399225912885e-05, 'epoch': 0.9755401161130675}\n",
            "{'loss': 1.41828076171875, 'learning_rate': 1.3417087021350848e-05, 'epoch': 0.9874369467973731}\n",
            "{'loss': 1.501359130859375, 'learning_rate': 1.333777481678881e-05, 'epoch': 0.9993337774816788}\n",
            "{'loss': 1.47530908203125, 'learning_rate': 1.325846261222677e-05, 'epoch': 1.0112306081659845}\n",
            "{'loss': 1.4486571044921874, 'learning_rate': 1.3179150407664734e-05, 'epoch': 1.0231274388502902}\n",
            "{'loss': 1.44993017578125, 'learning_rate': 1.3099838203102695e-05, 'epoch': 1.035024269534596}\n",
            "{'loss': 1.4332203369140626, 'learning_rate': 1.3020525998540657e-05, 'epoch': 1.0469211002189016}\n",
            "{'loss': 1.4504000244140625, 'learning_rate': 1.2941213793978618e-05, 'epoch': 1.0588179309032073}\n",
            "{'loss': 1.4196029052734376, 'learning_rate': 1.2861901589416581e-05, 'epoch': 1.070714761587513}\n",
            " 36% 45000/126084 [2:23:55<3:28:02,  6.50it/s][INFO|trainer.py:1162] 2020-12-10 16:18:39,579 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-45000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 16:18:39,587 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-45000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 16:18:41,579 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-45000/pytorch_model.bin\n",
            "{'loss': 1.4159853515625, 'learning_rate': 1.2782589384854543e-05, 'epoch': 1.0826115922718187}\n",
            "{'loss': 1.47365966796875, 'learning_rate': 1.2703277180292504e-05, 'epoch': 1.0945084229561246}\n",
            "{'loss': 1.4448736572265626, 'learning_rate': 1.2623964975730467e-05, 'epoch': 1.10640525364043}\n",
            "{'loss': 1.3962852783203126, 'learning_rate': 1.2544652771168429e-05, 'epoch': 1.118302084324736}\n",
            "{'loss': 1.4462440185546874, 'learning_rate': 1.246534056660639e-05, 'epoch': 1.1301989150090417}\n",
            "{'loss': 1.4159979248046874, 'learning_rate': 1.2386028362044353e-05, 'epoch': 1.1420957456933474}\n",
            "{'loss': 1.4088668212890625, 'learning_rate': 1.2306716157482314e-05, 'epoch': 1.153992576377653}\n",
            "{'loss': 1.415591552734375, 'learning_rate': 1.2227403952920276e-05, 'epoch': 1.1658894070619588}\n",
            "{'loss': 1.44053173828125, 'learning_rate': 1.2148091748358239e-05, 'epoch': 1.1777862377462645}\n",
            "{'loss': 1.4160465087890626, 'learning_rate': 1.20687795437962e-05, 'epoch': 1.1896830684305701}\n",
            " 40% 50000/126084 [2:39:55<5:15:54,  4.01it/s][INFO|trainer.py:1162] 2020-12-10 16:34:39,196 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-50000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 16:34:39,204 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-50000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 16:34:41,303 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-50000/pytorch_model.bin\n",
            "{'loss': 1.43329345703125, 'learning_rate': 1.1989467339234162e-05, 'epoch': 1.2015798991148758}\n",
            "{'loss': 1.433501220703125, 'learning_rate': 1.1910155134672123e-05, 'epoch': 1.2134767297991815}\n",
            "{'loss': 1.3885750732421875, 'learning_rate': 1.1830842930110086e-05, 'epoch': 1.2253735604834872}\n",
            "{'loss': 1.4018680419921874, 'learning_rate': 1.1751530725548048e-05, 'epoch': 1.237270391167793}\n",
            "{'loss': 1.4209779052734375, 'learning_rate': 1.1672218520986009e-05, 'epoch': 1.2491672218520986}\n",
            "{'loss': 1.404791015625, 'learning_rate': 1.1592906316423972e-05, 'epoch': 1.2610640525364043}\n",
            "{'loss': 1.3849603271484374, 'learning_rate': 1.1513594111861934e-05, 'epoch': 1.27296088322071}\n",
            "{'loss': 1.4261888427734375, 'learning_rate': 1.1434281907299895e-05, 'epoch': 1.2848577139050157}\n",
            "{'loss': 1.422630126953125, 'learning_rate': 1.135496970273786e-05, 'epoch': 1.2967545445893214}\n",
            "{'loss': 1.4317486572265625, 'learning_rate': 1.1275657498175821e-05, 'epoch': 1.308651375273627}\n",
            " 44% 55000/126084 [2:55:51<4:35:01,  4.31it/s][INFO|trainer.py:1162] 2020-12-10 16:50:35,112 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-55000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 16:50:35,120 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-55000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 16:50:37,423 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-55000/pytorch_model.bin\n",
            "{'loss': 1.40200244140625, 'learning_rate': 1.1196345293613781e-05, 'epoch': 1.3205482059579328}\n",
            "{'loss': 1.4041451416015625, 'learning_rate': 1.1117033089051746e-05, 'epoch': 1.3324450366422385}\n",
            "{'loss': 1.419024169921875, 'learning_rate': 1.1037720884489707e-05, 'epoch': 1.3443418673265441}\n",
            "{'loss': 1.3901103515625, 'learning_rate': 1.0958408679927669e-05, 'epoch': 1.3562386980108498}\n",
            "{'loss': 1.3931158447265626, 'learning_rate': 1.087909647536563e-05, 'epoch': 1.3681355286951555}\n",
            "{'loss': 1.369123291015625, 'learning_rate': 1.0799784270803593e-05, 'epoch': 1.3800323593794612}\n",
            "{'loss': 1.3735115966796876, 'learning_rate': 1.0720472066241555e-05, 'epoch': 1.3919291900637671}\n",
            "{'loss': 1.3894083251953124, 'learning_rate': 1.0641159861679516e-05, 'epoch': 1.4038260207480726}\n",
            "{'loss': 1.4267474365234376, 'learning_rate': 1.0561847657117479e-05, 'epoch': 1.4157228514323785}\n",
            "{'loss': 1.43438134765625, 'learning_rate': 1.048253545255544e-05, 'epoch': 1.427619682116684}\n",
            " 48% 60000/126084 [3:11:50<2:50:15,  6.47it/s][INFO|trainer.py:1162] 2020-12-10 17:06:33,656 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-60000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 17:06:33,663 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-60000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 17:06:35,805 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-60000/pytorch_model.bin\n",
            "{'loss': 1.373925537109375, 'learning_rate': 1.0403223247993402e-05, 'epoch': 1.43951651280099}\n",
            "{'loss': 1.3921251220703126, 'learning_rate': 1.0323911043431365e-05, 'epoch': 1.4514133434852954}\n",
            "{'loss': 1.4070416259765626, 'learning_rate': 1.0244598838869326e-05, 'epoch': 1.4633101741696013}\n",
            "{'loss': 1.3745792236328125, 'learning_rate': 1.0165286634307288e-05, 'epoch': 1.475207004853907}\n",
            "{'loss': 1.4412303466796874, 'learning_rate': 1.0085974429745251e-05, 'epoch': 1.4871038355382127}\n",
            "{'loss': 1.383175537109375, 'learning_rate': 1.0006662225183212e-05, 'epoch': 1.4990006662225184}\n",
            "{'loss': 1.3945191650390625, 'learning_rate': 9.927350020621174e-06, 'epoch': 1.510897496906824}\n",
            "{'loss': 1.3787674560546874, 'learning_rate': 9.848037816059137e-06, 'epoch': 1.5227943275911298}\n",
            "{'loss': 1.350146240234375, 'learning_rate': 9.768725611497098e-06, 'epoch': 1.5346911582754355}\n",
            "{'loss': 1.40643017578125, 'learning_rate': 9.68941340693506e-06, 'epoch': 1.5465879889597411}\n",
            " 52% 65000/126084 [3:27:44<2:36:15,  6.52it/s][INFO|trainer.py:1162] 2020-12-10 17:22:27,793 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-65000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 17:22:27,800 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-65000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 17:22:29,812 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-65000/pytorch_model.bin\n",
            "{'loss': 1.388456787109375, 'learning_rate': 9.610101202373023e-06, 'epoch': 1.5584848196440468}\n",
            "{'loss': 1.391848876953125, 'learning_rate': 9.530788997810984e-06, 'epoch': 1.5703816503283525}\n",
            "{'loss': 1.418347412109375, 'learning_rate': 9.451476793248946e-06, 'epoch': 1.5822784810126582}\n",
            "{'loss': 1.339224853515625, 'learning_rate': 9.372164588686909e-06, 'epoch': 1.594175311696964}\n",
            "{'loss': 1.3738074951171875, 'learning_rate': 9.29285238412487e-06, 'epoch': 1.6060721423812696}\n",
            "{'loss': 1.3791636962890625, 'learning_rate': 9.213540179562831e-06, 'epoch': 1.6179689730655753}\n",
            "{'loss': 1.37815966796875, 'learning_rate': 9.134227975000793e-06, 'epoch': 1.629865803749881}\n",
            "{'loss': 1.366653076171875, 'learning_rate': 9.054915770438756e-06, 'epoch': 1.6417626344341867}\n",
            "{'loss': 1.37652685546875, 'learning_rate': 8.975603565876717e-06, 'epoch': 1.6536594651184924}\n",
            "{'loss': 1.3477200927734374, 'learning_rate': 8.896291361314679e-06, 'epoch': 1.6655562958027983}\n",
            " 56% 70000/126084 [3:43:51<3:12:27,  4.86it/s][INFO|trainer.py:1162] 2020-12-10 17:38:35,453 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-70000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 17:38:35,460 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-70000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 17:38:38,010 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-70000/pytorch_model.bin\n",
            "{'loss': 1.3711514892578125, 'learning_rate': 8.816979156752642e-06, 'epoch': 1.6774531264871038}\n",
            "{'loss': 1.36434228515625, 'learning_rate': 8.737666952190605e-06, 'epoch': 1.6893499571714097}\n",
            "{'loss': 1.3474429931640626, 'learning_rate': 8.658354747628566e-06, 'epoch': 1.7012467878557151}\n",
            "{'loss': 1.371682373046875, 'learning_rate': 8.579042543066528e-06, 'epoch': 1.713143618540021}\n",
            "{'loss': 1.33780419921875, 'learning_rate': 8.49973033850449e-06, 'epoch': 1.7250404492243265}\n",
            "{'loss': 1.35546044921875, 'learning_rate': 8.420418133942452e-06, 'epoch': 1.7369372799086324}\n",
            "{'loss': 1.400231689453125, 'learning_rate': 8.341105929380414e-06, 'epoch': 1.748834110592938}\n",
            "{'loss': 1.344560791015625, 'learning_rate': 8.261793724818375e-06, 'epoch': 1.7607309412772438}\n",
            "{'loss': 1.3540030517578125, 'learning_rate': 8.182481520256338e-06, 'epoch': 1.7726277719615493}\n",
            "{'loss': 1.3549307861328126, 'learning_rate': 8.1031693156943e-06, 'epoch': 1.7845246026458552}\n",
            " 59% 75000/126084 [3:59:46<2:08:55,  6.60it/s][INFO|trainer.py:1162] 2020-12-10 17:54:29,713 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-75000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 17:54:29,720 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-75000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 17:54:31,682 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-75000/pytorch_model.bin\n",
            "{'loss': 1.3535501708984374, 'learning_rate': 8.023857111132261e-06, 'epoch': 1.7964214333301607}\n",
            "{'loss': 1.3281156005859376, 'learning_rate': 7.944544906570224e-06, 'epoch': 1.8083182640144666}\n",
            "{'loss': 1.367041748046875, 'learning_rate': 7.865232702008186e-06, 'epoch': 1.8202150946987723}\n",
            "{'loss': 1.3116705322265625, 'learning_rate': 7.785920497446147e-06, 'epoch': 1.832111925383078}\n",
            "{'loss': 1.3253607177734374, 'learning_rate': 7.70660829288411e-06, 'epoch': 1.8440087560673837}\n",
            "{'loss': 1.371666015625, 'learning_rate': 7.627296088322072e-06, 'epoch': 1.8559055867516894}\n",
            "{'loss': 1.337885986328125, 'learning_rate': 7.547983883760034e-06, 'epoch': 1.867802417435995}\n",
            "{'loss': 1.32781640625, 'learning_rate': 7.468671679197995e-06, 'epoch': 1.8796992481203008}\n",
            "{'loss': 1.3570908203125, 'learning_rate': 7.3893594746359575e-06, 'epoch': 1.8915960788046065}\n",
            "{'loss': 1.3282093505859376, 'learning_rate': 7.31004727007392e-06, 'epoch': 1.9034929094889121}\n",
            " 63% 80000/126084 [4:15:30<1:54:54,  6.68it/s][INFO|trainer.py:1162] 2020-12-10 18:10:14,186 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-80000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 18:10:14,194 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-80000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 18:10:16,778 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-80000/pytorch_model.bin\n",
            "{'loss': 1.3515216064453126, 'learning_rate': 7.230735065511881e-06, 'epoch': 1.9153897401732178}\n",
            "{'loss': 1.375976806640625, 'learning_rate': 7.1514228609498434e-06, 'epoch': 1.9272865708575235}\n",
            "{'loss': 1.3407242431640625, 'learning_rate': 7.072110656387805e-06, 'epoch': 1.9391834015418292}\n",
            "{'loss': 1.3657584228515625, 'learning_rate': 6.992798451825767e-06, 'epoch': 1.951080232226135}\n",
            "{'loss': 1.3213375244140626, 'learning_rate': 6.91348624726373e-06, 'epoch': 1.9629770629104406}\n",
            "{'loss': 1.3331124267578125, 'learning_rate': 6.834174042701691e-06, 'epoch': 1.9748738935947463}\n",
            "{'loss': 1.3208193359375, 'learning_rate': 6.754861838139654e-06, 'epoch': 1.9867707242790522}\n",
            "{'loss': 1.3137593994140624, 'learning_rate': 6.675549633577616e-06, 'epoch': 1.9986675549633577}\n",
            "{'loss': 1.3160703125, 'learning_rate': 6.5962374290155776e-06, 'epoch': 2.0105643856476636}\n",
            "{'loss': 1.336419189453125, 'learning_rate': 6.51692522445354e-06, 'epoch': 2.022461216331969}\n",
            " 67% 85000/126084 [4:31:26<2:21:50,  4.83it/s][INFO|trainer.py:1162] 2020-12-10 18:26:09,767 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-85000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 18:26:09,777 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-85000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 18:26:12,144 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-85000/pytorch_model.bin\n",
            "{'loss': 1.330939208984375, 'learning_rate': 6.437613019891501e-06, 'epoch': 2.034358047016275}\n",
            "{'loss': 1.358671875, 'learning_rate': 6.3583008153294635e-06, 'epoch': 2.0462548777005805}\n",
            "{'loss': 1.32644482421875, 'learning_rate': 6.278988610767426e-06, 'epoch': 2.0581517083848864}\n",
            "{'loss': 1.30646337890625, 'learning_rate': 6.199676406205387e-06, 'epoch': 2.070048539069192}\n",
            "{'loss': 1.3004786376953126, 'learning_rate': 6.120364201643349e-06, 'epoch': 2.0819453697534978}\n",
            "{'loss': 1.3159735107421875, 'learning_rate': 6.041051997081311e-06, 'epoch': 2.0938422004378032}\n",
            "{'loss': 1.3046263427734375, 'learning_rate': 5.961739792519273e-06, 'epoch': 2.105739031122109}\n",
            "{'loss': 1.332855712890625, 'learning_rate': 5.882427587957235e-06, 'epoch': 2.1176358618064146}\n",
            "{'loss': 1.2915374755859375, 'learning_rate': 5.803115383395197e-06, 'epoch': 2.1295326924907205}\n",
            "{'loss': 1.3262012939453125, 'learning_rate': 5.723803178833159e-06, 'epoch': 2.141429523175026}\n",
            " 71% 90000/126084 [4:47:19<1:37:04,  6.20it/s][INFO|trainer.py:1162] 2020-12-10 18:42:03,268 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-90000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 18:42:03,276 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-90000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 18:42:05,435 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-90000/pytorch_model.bin\n",
            "{'loss': 1.277869140625, 'learning_rate': 5.644490974271122e-06, 'epoch': 2.153326353859332}\n",
            "{'loss': 1.330125244140625, 'learning_rate': 5.5651787697090835e-06, 'epoch': 2.1652231845436374}\n",
            "{'loss': 1.3112530517578125, 'learning_rate': 5.485866565147046e-06, 'epoch': 2.1771200152279433}\n",
            "{'loss': 1.3226414794921875, 'learning_rate': 5.406554360585007e-06, 'epoch': 2.189016845912249}\n",
            "{'loss': 1.30358251953125, 'learning_rate': 5.3272421560229695e-06, 'epoch': 2.2009136765965547}\n",
            "{'loss': 1.32408935546875, 'learning_rate': 5.247929951460932e-06, 'epoch': 2.21281050728086}\n",
            "{'loss': 1.3363336181640626, 'learning_rate': 5.168617746898893e-06, 'epoch': 2.224707337965166}\n",
            "{'loss': 1.283467041015625, 'learning_rate': 5.089305542336855e-06, 'epoch': 2.236604168649472}\n",
            "{'loss': 1.351594482421875, 'learning_rate': 5.009993337774817e-06, 'epoch': 2.2485009993337775}\n",
            "{'loss': 1.259851318359375, 'learning_rate': 4.930681133212779e-06, 'epoch': 2.2603978300180834}\n",
            " 75% 95000/126084 [5:03:11<1:30:21,  5.73it/s][INFO|trainer.py:1162] 2020-12-10 18:57:54,666 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-95000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 18:57:54,673 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-95000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 18:57:56,654 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-95000/pytorch_model.bin\n",
            "{'loss': 1.3176539306640624, 'learning_rate': 4.851368928650741e-06, 'epoch': 2.272294660702389}\n",
            "{'loss': 1.2915069580078125, 'learning_rate': 4.7720567240887036e-06, 'epoch': 2.2841914913866948}\n",
            "{'loss': 1.307956787109375, 'learning_rate': 4.692744519526665e-06, 'epoch': 2.296088322071}\n",
            "{'loss': 1.2970152587890624, 'learning_rate': 4.613432314964627e-06, 'epoch': 2.307985152755306}\n",
            "{'loss': 1.3226334228515626, 'learning_rate': 4.534120110402589e-06, 'epoch': 2.3198819834396116}\n",
            "{'loss': 1.328885498046875, 'learning_rate': 4.454807905840552e-06, 'epoch': 2.3317788141239175}\n",
            "{'loss': 1.29825244140625, 'learning_rate': 4.375495701278513e-06, 'epoch': 2.343675644808223}\n",
            "{'loss': 1.354317138671875, 'learning_rate': 4.296183496716475e-06, 'epoch': 2.355572475492529}\n",
            "{'loss': 1.34700048828125, 'learning_rate': 4.216871292154437e-06, 'epoch': 2.3674693061768344}\n",
            "{'loss': 1.3208841552734376, 'learning_rate': 4.137559087592399e-06, 'epoch': 2.3793661368611403}\n",
            " 79% 100000/126084 [5:19:03<2:05:34,  3.46it/s][INFO|trainer.py:1162] 2020-12-10 19:13:47,230 >> Saving model checkpoint to /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-100000\n",
            "[INFO|configuration_utils.py:281] 2020-12-10 19:13:47,237 >> Configuration saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-100000/config.json\n",
            "[INFO|modeling_utils.py:741] 2020-12-10 19:13:49,346 >> Model weights saved in /content/drive/MyDrive/abnormal-distribution-project-data/lean/models/checkpoint-100000/pytorch_model.bin\n",
            "{'loss': 1.305293212890625, 'learning_rate': 4.058246883030361e-06, 'epoch': 2.3912629675454458}\n",
            " 80% 100565/126084 [5:21:00<1:04:34,  6.59it/s]Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/abnormal-distribution-project-data/lean/run_mlm.py\", line 392, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/abnormal-distribution-project-data/lean/run_mlm.py\", line 362, in main\n",
            "    trainer.train(model_path=model_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\", line 761, in train\n",
            "    torch.nn.utils.clip_grad_norm_(model.parameters(), self.args.max_grad_norm)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/utils/clip_grad.py\", line 38, in clip_grad_norm_\n",
            "    if clip_coef < 1:\n",
            "KeyboardInterrupt\n",
            " 80% 100565/126084 [5:21:01<1:21:27,  5.22it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCPaCRrHz92L",
        "outputId": "962723a9-97e9-4fd8-ff0f-0f14f57a9cea"
      },
      "source": [
        "!python run_mlm.py --model_name_or_path bert-base-uncased --train_file /content/drive/MyDrive/abnormal-distribution-project-data/lean/minitrain.txt --validation_file /content/drive/MyDrive/abnormal-distribution-project-data/lean/valid.txt --output_dir /content/drive/MyDrive/abnormal-distribution-project-data/lean/results --do_eval --line_by_line"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 04:47:38.325381: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "12/10/2020 04:47:39 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "12/10/2020 04:47:39 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='/content/drive/MyDrive/abnormal-distribution-project-data/lean/results', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec10_04-47-39_96773465fb31', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='/content/drive/MyDrive/abnormal-distribution-project-data/lean/results', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Using custom data configuration default\n",
            "Reusing dataset text (/root/.cache/huggingface/datasets/text/default-d5d618c48fbef382/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n",
            "12/10/2020 04:47:40 - INFO - filelock -   Lock 140237747185592 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170.lock\n",
            "[INFO|file_utils.py:1214] 2020-12-10 04:47:40,851 >> https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwmi4c34h\n",
            "Downloading: 100% 433/433 [00:00<00:00, 543kB/s]\n",
            "[INFO|file_utils.py:1218] 2020-12-10 04:47:41,070 >> storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\n",
            "[INFO|file_utils.py:1221] 2020-12-10 04:47:41,070 >> creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\n",
            "12/10/2020 04:47:41 - INFO - filelock -   Lock 140237747185592 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170.lock\n",
            "[INFO|configuration_utils.py:411] 2020-12-10 04:47:41,071 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\n",
            "[INFO|configuration_utils.py:447] 2020-12-10 04:47:41,071 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:411] 2020-12-10 04:47:41,279 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170\n",
            "[INFO|configuration_utils.py:447] 2020-12-10 04:47:41,280 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/10/2020 04:47:41 - INFO - filelock -   Lock 140235304793648 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
            "[INFO|file_utils.py:1214] 2020-12-10 04:47:41,633 >> https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpfqluev1t\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 877kB/s]\n",
            "[INFO|file_utils.py:1218] 2020-12-10 04:47:42,111 >> storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "[INFO|file_utils.py:1221] 2020-12-10 04:47:42,111 >> creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "12/10/2020 04:47:42 - INFO - filelock -   Lock 140235304793648 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
            "12/10/2020 04:47:42 - INFO - filelock -   Lock 140235304795888 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
            "[INFO|file_utils.py:1214] 2020-12-10 04:47:42,327 >> https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_01tyzab\n",
            "Downloading: 100% 466k/466k [00:00<00:00, 1.47MB/s]\n",
            "[INFO|file_utils.py:1218] 2020-12-10 04:47:42,853 >> storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "[INFO|file_utils.py:1221] 2020-12-10 04:47:42,853 >> creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "12/10/2020 04:47:42 - INFO - filelock -   Lock 140235304795888 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
            "[INFO|tokenization_utils_base.py:1768] 2020-12-10 04:47:42,854 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "[INFO|tokenization_utils_base.py:1768] 2020-12-10 04:47:42,854 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "12/10/2020 04:47:43 - INFO - filelock -   Lock 140237747185592 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
            "[INFO|file_utils.py:1214] 2020-12-10 04:47:43,110 >> https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpc4r2vqxh\n",
            "Downloading: 100% 440M/440M [00:05<00:00, 82.2MB/s]\n",
            "[INFO|file_utils.py:1218] 2020-12-10 04:47:48,535 >> storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "[INFO|file_utils.py:1221] 2020-12-10 04:47:48,535 >> creating metadata file for /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "12/10/2020 04:47:48 - INFO - filelock -   Lock 140237747185592 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
            "[INFO|modeling_utils.py:940] 2020-12-10 04:47:48,536 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "[WARNING|modeling_utils.py:1048] 2020-12-10 04:47:52,587 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[INFO|modeling_utils.py:1065] 2020-12-10 04:47:52,587 >> All the weights of BertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
            "100% 1/1 [00:00<00:00, 15.04ba/s]\n",
            "100% 25/25 [00:03<00:00,  7.28ba/s]\n",
            "[INFO|trainer.py:357] 2020-12-10 04:48:01,250 >> The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: special_tokens_mask.\n",
            "12/10/2020 04:48:01 - INFO - __main__ -   *** Evaluate ***\n",
            "[INFO|trainer.py:1333] 2020-12-10 04:48:01,251 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:1334] 2020-12-10 04:48:01,251 >>   Num examples = 23133\n",
            "[INFO|trainer.py:1335] 2020-12-10 04:48:01,251 >>   Batch size = 8\n",
            "100% 2892/2892 [03:51<00:00, 12.52it/s]\n",
            "12/10/2020 04:51:52 - INFO - __main__ -   ***** Eval results *****\n",
            "12/10/2020 04:51:52 - INFO - __main__ -     perplexity = 26.925701688829495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMrVtDNW_WvN",
        "outputId": "cf3f5a81-926f-4063-ec36-9d692acb66de"
      },
      "source": [
        "!python run_mlm.py --model_name_or_path /content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-310000 --train_file /content/drive/MyDrive/abnormal-distribution-project-data/lean/minitrain.txt --validation_file /content/drive/MyDrive/abnormal-distribution-project-data/lean/valid.txt --output_dir /content/drive/MyDrive/abnormal-distribution-project-data/lean/results --do_eval --line_by_line"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-10 04:52:40.090053: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "12/10/2020 04:52:41 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "12/10/2020 04:52:41 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='/content/drive/MyDrive/abnormal-distribution-project-data/lean/results', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Dec10_04-52-41_96773465fb31', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='/content/drive/MyDrive/abnormal-distribution-project-data/lean/results', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Using custom data configuration default\n",
            "Reusing dataset text (/root/.cache/huggingface/datasets/text/default-d5d618c48fbef382/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n",
            "[INFO|configuration_utils.py:409] 2020-12-10 04:52:43,560 >> loading configuration file /content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-310000/config.json\n",
            "[INFO|configuration_utils.py:447] 2020-12-10 04:52:43,560 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:409] 2020-12-10 04:52:43,562 >> loading configuration file /content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-310000/config.json\n",
            "[INFO|configuration_utils.py:447] 2020-12-10 04:52:43,562 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1688] 2020-12-10 04:52:43,563 >> Model name '/content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-310000' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming '/content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-310000' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "[INFO|tokenization_utils_base.py:1721] 2020-12-10 04:52:43,564 >> Didn't find file /content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-310000/tokenizer.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1721] 2020-12-10 04:52:43,564 >> Didn't find file /content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-310000/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1766] 2020-12-10 04:52:43,566 >> loading file /content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-310000/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1766] 2020-12-10 04:52:43,566 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1766] 2020-12-10 04:52:43,566 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1766] 2020-12-10 04:52:43,566 >> loading file /content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-310000/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1766] 2020-12-10 04:52:43,567 >> loading file /content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-310000/tokenizer_config.json\n",
            "[INFO|modeling_utils.py:938] 2020-12-10 04:52:46,039 >> loading weights file /content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-310000/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1056] 2020-12-10 04:52:59,816 >> All model checkpoint weights were used when initializing BertForMaskedLM.\n",
            "\n",
            "[INFO|modeling_utils.py:1065] 2020-12-10 04:52:59,816 >> All the weights of BertForMaskedLM were initialized from the model checkpoint at /content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-310000.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
            "100% 1/1 [00:00<00:00, 39.33ba/s]\n",
            "100% 25/25 [00:03<00:00,  7.34ba/s]\n",
            "[INFO|trainer.py:357] 2020-12-10 04:53:08,331 >> The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: special_tokens_mask.\n",
            "12/10/2020 04:53:08 - INFO - __main__ -   *** Evaluate ***\n",
            "[INFO|trainer.py:1333] 2020-12-10 04:53:08,331 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:1334] 2020-12-10 04:53:08,331 >>   Num examples = 23133\n",
            "[INFO|trainer.py:1335] 2020-12-10 04:53:08,331 >>   Batch size = 8\n",
            "100% 2892/2892 [03:51<00:00, 12.51it/s]\n",
            "12/10/2020 04:56:59 - INFO - __main__ -   ***** Eval results *****\n",
            "12/10/2020 04:56:59 - INFO - __main__ -     perplexity = 5.76818368205212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh0onDiXz940"
      },
      "source": [
        "/content/drive/MyDrive/abnormal-distribution-project-data/lean/model/checkpoint-5000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPatpx0t_3Gp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}